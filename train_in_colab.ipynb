{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6vHqHCav9pW",
        "outputId": "6af16f72-8e7e-47c7-c84a-43aaee01a7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "GPU is available: True\n",
            "GPU model: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install transformers tensorboard\n",
        "\n",
        "# Create project structure\n",
        "!mkdir -p src/models src/data src/training data\n",
        "\n",
        "# Check if GPU is available\n",
        "import torch\n",
        "print(\"GPU is available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU model:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import sys\n",
        "\n",
        "modules_to_reload = ['src.models.chatbot', 'src.training.train_baseline']\n",
        "for module in modules_to_reload:\n",
        "    if module in sys.modules:\n",
        "        del sys.modules[module]\n",
        "\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksIBbG9x7lgS",
        "outputId": "370abe0c-c806-4b4b-9186-29f9d8e26d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.models.chatbot import RestaurantChatbot\n",
        "from src.training.train_baseline import train_baseline\n",
        "\n",
        "metrics = train_baseline(\n",
        "    train_path='data/train.json',\n",
        "    val_path='data/val.json',\n",
        "    output_dir='models/baseline',\n",
        "    num_epochs=8,\n",
        "    batch_size=24,\n",
        "    warmup_steps=500,\n",
        "    max_length=128,\n",
        "    max_train_samples=8000,\n",
        "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ],
      "metadata": {
        "id": "lV4sK3aIzEwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7772cb8b-5545-4685-c38a-611237ae95b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Training on 8000 samples for 8 epochs\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/8:   0%|          | 0/375 [00:00<?, ?it/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "Epoch 1/8:  89%|████████▉ | 333/375 [04:40<00:35,  1.19it/s, loss=2.53]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.76it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1:\n",
            "Average training loss: 2.8581\n",
            "Average validation loss: 2.3304\n",
            "New best model saved with validation loss: 2.3304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.18it/s, loss=2.32]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2:\n",
            "Average training loss: 2.3410\n",
            "Average validation loss: 2.2370\n",
            "New best model saved with validation loss: 2.2370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.18it/s, loss=2.11]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3:\n",
            "Average training loss: 2.2110\n",
            "Average validation loss: 2.1945\n",
            "New best model saved with validation loss: 2.1945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.18it/s, loss=1.86]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4:\n",
            "Average training loss: 2.1325\n",
            "Average validation loss: 2.1682\n",
            "New best model saved with validation loss: 2.1682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.17it/s, loss=2.1]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5:\n",
            "Average training loss: 2.0711\n",
            "Average validation loss: 2.1526\n",
            "New best model saved with validation loss: 2.1526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.18it/s, loss=2.05]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6:\n",
            "Average training loss: 2.0136\n",
            "Average validation loss: 2.1457\n",
            "New best model saved with validation loss: 2.1457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.17it/s, loss=1.93]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7:\n",
            "Average training loss: 1.9802\n",
            "Average validation loss: 2.1381\n",
            "New best model saved with validation loss: 2.1381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8:  89%|████████▉ | 333/375 [04:43<00:35,  1.18it/s, loss=2.12]\n",
            "Validation: 100%|██████████| 42/42 [00:11<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8:\n",
            "Average training loss: 1.9509\n",
            "Average validation loss: 2.1366\n",
            "New best model saved with validation loss: 2.1366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r models.zip models/\n",
        "\n",
        "# Then download it (this will appear in Colab's file browser)\n",
        "from google.colab import files\n",
        "files.download('models.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "GEOQYdRfItoh",
        "outputId": "a45fe85f-e027-46ef-e7a1-7dc6d0afd217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: models/ (stored 0%)\n",
            "  adding: models/baseline/ (stored 0%)\n",
            "  adding: models/baseline/best_model.pt (deflated 7%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29f0a593-486d-4345-ac5d-2e73b0665fa7\", \"models.zip\", 462374510)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.chat_with_bot import chat_with_bot"
      ],
      "metadata": {
        "id": "ERN6NWv8kkMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_with_bot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz1eq1mfLYt1",
        "outputId": "e1ad64bc-8da3-4dfa-c86c-137ea70b74b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Restaurant Chatbot is ready! Type 'quit' to exit.\n",
            "Ask me about restaurant recommendations, cuisine types, or specific dishes.\n",
            "\n",
            "Bot:  can you give me an italian place in san francisco? [SEP] Based on the reviews, JW Marriott Santa Barbara at 2100 N Virginia St is a great option. I went here for the first time last week. I was excited about the view from the balcony overlooking the ocean. It was amazing! I had a hard time choosing between the two hotels that I had visited before. I decided to go with the Santa Barbara hotel. It was a great choice because it is close to the beach and the beach is close to the airport. I had a nice view of the ocean. The pool was nice and the patio 😟\n",
            "\n",
            "Bot:  what about a restaurant? [SEP] Based on the reviews, The Cuban Sandwich Shop at 809 W Carrillo St is a great a restaurant at 809 W Carrillo St. I'm so happy that I finally found this place.  I'm from out of town and have never been here before.  I love their sandwiches and salsa.  They have a great variety of meats and cheeses.  The best part is the staff is always nice and attentive.  I always get the fried shrimp sandwich with a side of chicken.  I've had the chicken with the chicken and the fries with the chicken.  😟\n"
          ]
        }
      ]
    }
  ]
}